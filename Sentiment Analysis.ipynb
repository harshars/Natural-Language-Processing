{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "## Importing alsl the required packages\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import string\n",
    "import random\n",
    "from nltk.corpus import subjectivity,stopwords\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from unidecode import unidecode\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.util import extract_unigram_feats, mark_negation\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Movie review dataset for classifying the reviews into Positive or negative\n",
    "movieReview = pd.read_csv('labeledTrainDataSentiment.tsv',delimiter='\\t')\n",
    "\n",
    "### For the analysis we ll consider only 1000 rows\n",
    "movieReview_head = movieReview[0:1000]\n",
    "\n",
    "movieReview_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing \n",
    "def clean_text(text):\n",
    "    return text.replace(\"\\\\\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\The Classic War of the Worlds\\\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells\\' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\\\"critics\\\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\\\"critics\\\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells\\' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\\\"critics\\\\\" perceive to be its shortcomings.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieReview[\"review\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Classic War of the Worlds \" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells\\' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur  \"critics \" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the  \"critics \". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells\\' classic novel, and we found it to be very entertaining. This made it easy to overlook what the  \"critics \" perceive to be its shortcomings.\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(movieReview[\"review\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1 : Using Bag of Words Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Step 1: Sentence tokenize and then word tokenize the statements\n",
    "### Step 2: Clean the given words and do lemmatization / stemming based on sthe use case\n",
    "### Step 3: Case conversion is done before checking the word is present in positive or negative corpus\n",
    "### Step 4: Check whether the words are present either in the positive corpus or negative corpus\n",
    "### Step 5: If found in the positive corpus then score of 1 is given and if found in negative corpus then score of -1 is given\n",
    "### Step 6: Total score of the statement is the sum of the scores of each individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### regex to split the sentences into words\n",
    "nltk_tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "def split(text):\n",
    "    \n",
    "    ### Split is used for converting a paragraph into statements\n",
    "    ### Sentence tokenizer can also be used for sentence split (Alternative)\n",
    "    text = \"\".join([ch for ch in text if ord(ch)<= 128])\n",
    "    sentences = text.split('. ') \n",
    "\n",
    "    \n",
    "    ### regex is used for word split, instead of this word tokenizer can also be usesd\n",
    "    tokenized_sentences = [nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\The Classic War of the Worlds\\\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells\\' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\\\"critics\\\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\\\"critics\\\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells\\' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\\\"critics\\\\\" perceive to be its shortcomings.\"'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieReview[\"review\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Classic',\n",
       "  'War',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Worlds',\n",
       "  'by',\n",
       "  'Timothy',\n",
       "  'Hines',\n",
       "  'is',\n",
       "  'a',\n",
       "  'very',\n",
       "  'entertaining',\n",
       "  'film',\n",
       "  'that',\n",
       "  'obviously',\n",
       "  'goes',\n",
       "  'to',\n",
       "  'great',\n",
       "  'effort',\n",
       "  'and',\n",
       "  'lengths',\n",
       "  'to',\n",
       "  'faithfully',\n",
       "  'recreate',\n",
       "  'H'],\n",
       " ['G'],\n",
       " ['Wells', 'classic', 'book'],\n",
       " ['Mr'],\n",
       " ['Hines', 'succeeds', 'in', 'doing', 'so'],\n",
       " ['I',\n",
       "  'and',\n",
       "  'those',\n",
       "  'who',\n",
       "  'watched',\n",
       "  'his',\n",
       "  'film',\n",
       "  'with',\n",
       "  'me',\n",
       "  'appreciated',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'it',\n",
       "  'was',\n",
       "  'not',\n",
       "  'the',\n",
       "  'standard',\n",
       "  'predictable',\n",
       "  'Hollywood',\n",
       "  'fare',\n",
       "  'that',\n",
       "  'comes',\n",
       "  'out',\n",
       "  'every',\n",
       "  'year',\n",
       "  'e',\n",
       "  'g'],\n",
       " ['the',\n",
       "  'Spielberg',\n",
       "  'version',\n",
       "  'with',\n",
       "  'Tom',\n",
       "  'Cruise',\n",
       "  'that',\n",
       "  'had',\n",
       "  'only',\n",
       "  'the',\n",
       "  'slightest',\n",
       "  'resemblance',\n",
       "  'to',\n",
       "  'the',\n",
       "  'book'],\n",
       " ['Obviously',\n",
       "  'everyone',\n",
       "  'looks',\n",
       "  'for',\n",
       "  'different',\n",
       "  'things',\n",
       "  'in',\n",
       "  'a',\n",
       "  'movie'],\n",
       " ['Those',\n",
       "  'who',\n",
       "  'envision',\n",
       "  'themselves',\n",
       "  'as',\n",
       "  'amateur',\n",
       "  'critics',\n",
       "  'look',\n",
       "  'only',\n",
       "  'to',\n",
       "  'criticize',\n",
       "  'everything',\n",
       "  'they',\n",
       "  'can'],\n",
       " ['Others',\n",
       "  'rate',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'on',\n",
       "  'more',\n",
       "  'important',\n",
       "  'bases',\n",
       "  'like',\n",
       "  'being',\n",
       "  'entertained',\n",
       "  'which',\n",
       "  'is',\n",
       "  'why',\n",
       "  'most',\n",
       "  'people',\n",
       "  'never',\n",
       "  'agree',\n",
       "  'with',\n",
       "  'the',\n",
       "  'critics'],\n",
       " ['We', 'enjoyed', 'the', 'effort', 'Mr'],\n",
       " ['Hines', 'put', 'into', 'being', 'faithful', 'to', 'H', 'G'],\n",
       " ['Wells',\n",
       "  'classic',\n",
       "  'novel',\n",
       "  'and',\n",
       "  'we',\n",
       "  'found',\n",
       "  'it',\n",
       "  'to',\n",
       "  'be',\n",
       "  'very',\n",
       "  'entertaining'],\n",
       " ['This',\n",
       "  'made',\n",
       "  'it',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'overlook',\n",
       "  'what',\n",
       "  'the',\n",
       "  'critics',\n",
       "  'perceive',\n",
       "  'to',\n",
       "  'be',\n",
       "  'its',\n",
       "  'shortcomings']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(movieReview[\"review\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the positive and negative corpus and storing it in the training dictionary\n",
    "\n",
    "training_dictionary = {}\n",
    "\n",
    "### Positive corpus\n",
    "with open('pos.txt') as fp:\n",
    "    for line in fp:\n",
    "        training_dictionary[line.split('\\n')[0].strip()] = 1\n",
    "\n",
    "### Negative corpus        \n",
    "with open('neg.txt') as fp:\n",
    "    for line in fp:\n",
    "        training_dictionary[line.split('\\n')[0].strip()] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a+': 1,\n",
       " 'abound': 1,\n",
       " 'abounds': 1,\n",
       " 'abundance': 1,\n",
       " 'abundant': 1,\n",
       " 'accessable': 1,\n",
       " 'accessible': 1,\n",
       " 'acclaim': 1,\n",
       " 'acclaimed': 1,\n",
       " 'acclamation': 1,\n",
       " 'accolade': 1,\n",
       " 'accolades': 1,\n",
       " 'accommodative': 1,\n",
       " 'accomodative': 1,\n",
       " 'accomplish': 1,\n",
       " 'accomplished': 1,\n",
       " 'accomplishment': 1,\n",
       " 'accomplishments': 1,\n",
       " 'accurate': 1,\n",
       " 'accurately': 1,\n",
       " 'achievable': 1,\n",
       " 'achievement': 1,\n",
       " 'achievements': 1,\n",
       " 'achievible': 1,\n",
       " 'acumen': 1,\n",
       " 'adaptable': 1,\n",
       " 'adaptive': 1,\n",
       " 'adequate': 1,\n",
       " 'adjustable': 1,\n",
       " 'admirable': 1,\n",
       " 'admirably': 1,\n",
       " 'admiration': 1,\n",
       " 'admire': 1,\n",
       " 'admirer': 1,\n",
       " 'admiring': 1,\n",
       " 'admiringly': 1,\n",
       " 'adorable': 1,\n",
       " 'adore': 1,\n",
       " 'adored': 1,\n",
       " 'adorer': 1,\n",
       " 'adoring': 1,\n",
       " 'adoringly': 1,\n",
       " 'adroit': 1,\n",
       " 'adroitly': 1,\n",
       " 'adulate': 1,\n",
       " 'adulation': 1,\n",
       " 'adulatory': 1,\n",
       " 'advanced': 1,\n",
       " 'advantage': 1,\n",
       " 'advantageous': 1,\n",
       " 'advantageously': 1,\n",
       " 'advantages': 1,\n",
       " 'adventuresome': 1,\n",
       " 'adventurous': 1,\n",
       " 'advocate': 1,\n",
       " 'advocated': 1,\n",
       " 'advocates': 1,\n",
       " 'affability': 1,\n",
       " 'affable': 1,\n",
       " 'affably': 1,\n",
       " 'affectation': 1,\n",
       " 'affection': 1,\n",
       " 'affectionate': 1,\n",
       " 'affinity': 1,\n",
       " 'affirm': 1,\n",
       " 'affirmation': 1,\n",
       " 'affirmative': 1,\n",
       " 'affluence': 1,\n",
       " 'affluent': 1,\n",
       " 'afford': 1,\n",
       " 'affordable': 1,\n",
       " 'affordably': 1,\n",
       " 'afordable': 1,\n",
       " 'agile': 1,\n",
       " 'agilely': 1,\n",
       " 'agility': 1,\n",
       " 'agreeable': 1,\n",
       " 'agreeableness': 1,\n",
       " 'agreeably': 1,\n",
       " 'all-around': 1,\n",
       " 'alluring': 1,\n",
       " 'alluringly': 1,\n",
       " 'altruistic': 1,\n",
       " 'altruistically': 1,\n",
       " 'amaze': 1,\n",
       " 'amazed': 1,\n",
       " 'amazement': 1,\n",
       " 'amazes': 1,\n",
       " 'amazing': 1,\n",
       " 'amazingly': 1,\n",
       " 'ambitious': 1,\n",
       " 'ambitiously': 1,\n",
       " 'ameliorate': 1,\n",
       " 'amenable': 1,\n",
       " 'amenity': 1,\n",
       " 'amiability': 1,\n",
       " 'amiabily': 1,\n",
       " 'amiable': 1,\n",
       " 'amicability': 1,\n",
       " 'amicable': 1,\n",
       " 'amicably': 1,\n",
       " 'amity': 1,\n",
       " 'ample': 1,\n",
       " 'amply': 1,\n",
       " 'amuse': 1,\n",
       " 'amusing': 1,\n",
       " 'amusingly': 1,\n",
       " 'angel': 1,\n",
       " 'angelic': 1,\n",
       " 'apotheosis': 1,\n",
       " 'appeal': 1,\n",
       " 'appealing': 1,\n",
       " 'applaud': 1,\n",
       " 'appreciable': 1,\n",
       " 'appreciate': 1,\n",
       " 'appreciated': 1,\n",
       " 'appreciates': 1,\n",
       " 'appreciative': 1,\n",
       " 'appreciatively': 1,\n",
       " 'appropriate': 1,\n",
       " 'approval': 1,\n",
       " 'approve': 1,\n",
       " 'ardent': 1,\n",
       " 'ardently': 1,\n",
       " 'ardor': 1,\n",
       " 'articulate': 1,\n",
       " 'aspiration': 1,\n",
       " 'aspirations': 1,\n",
       " 'aspire': 1,\n",
       " 'assurance': 1,\n",
       " 'assurances': 1,\n",
       " 'assure': 1,\n",
       " 'assuredly': 1,\n",
       " 'assuring': 1,\n",
       " 'astonish': 1,\n",
       " 'astonished': 1,\n",
       " 'astonishing': 1,\n",
       " 'astonishingly': 1,\n",
       " 'astonishment': 1,\n",
       " 'astound': 1,\n",
       " 'astounded': 1,\n",
       " 'astounding': 1,\n",
       " 'astoundingly': 1,\n",
       " 'astutely': 1,\n",
       " 'attentive': 1,\n",
       " 'attraction': 1,\n",
       " 'attractive': 1,\n",
       " 'attractively': 1,\n",
       " 'attune': 1,\n",
       " 'audible': 1,\n",
       " 'audibly': 1,\n",
       " 'auspicious': 1,\n",
       " 'authentic': 1,\n",
       " 'authoritative': 1,\n",
       " 'autonomous': 1,\n",
       " 'available': 1,\n",
       " 'aver': 1,\n",
       " 'avid': 1,\n",
       " 'avidly': 1,\n",
       " 'award': 1,\n",
       " 'awarded': 1,\n",
       " 'awards': 1,\n",
       " 'awe': 1,\n",
       " 'awed': 1,\n",
       " 'awesome': 1,\n",
       " 'awesomely': 1,\n",
       " 'awesomeness': 1,\n",
       " 'awestruck': 1,\n",
       " 'awsome': 1,\n",
       " 'backbone': 1,\n",
       " 'balanced': 1,\n",
       " 'bargain': 1,\n",
       " 'beauteous': 1,\n",
       " 'beautiful': 1,\n",
       " 'beautifullly': 1,\n",
       " 'beautifully': 1,\n",
       " 'beautify': 1,\n",
       " 'beauty': 1,\n",
       " 'beckon': 1,\n",
       " 'beckoned': 1,\n",
       " 'beckoning': 1,\n",
       " 'beckons': 1,\n",
       " 'believable': 1,\n",
       " 'believeable': 1,\n",
       " 'beloved': 1,\n",
       " 'benefactor': 1,\n",
       " 'beneficent': 1,\n",
       " 'beneficial': 1,\n",
       " 'beneficially': 1,\n",
       " 'beneficiary': 1,\n",
       " 'benefit': 1,\n",
       " 'benefits': 1,\n",
       " 'benevolence': 1,\n",
       " 'benevolent': 1,\n",
       " 'benifits': 1,\n",
       " 'best': 1,\n",
       " 'best-known': 1,\n",
       " 'best-performing': 1,\n",
       " 'best-selling': 1,\n",
       " 'better': 1,\n",
       " 'better-known': 1,\n",
       " 'better-than-expected': 1,\n",
       " 'beutifully': 1,\n",
       " 'blameless': 1,\n",
       " 'bless': 1,\n",
       " 'blessing': 1,\n",
       " 'bliss': 1,\n",
       " 'blissful': 1,\n",
       " 'blissfully': 1,\n",
       " 'blithe': 1,\n",
       " 'blockbuster': 1,\n",
       " 'bloom': 1,\n",
       " 'blossom': 1,\n",
       " 'bolster': 1,\n",
       " 'bonny': 1,\n",
       " 'bonus': 1,\n",
       " 'bonuses': 1,\n",
       " 'boom': 1,\n",
       " 'booming': 1,\n",
       " 'boost': 1,\n",
       " 'boundless': 1,\n",
       " 'bountiful': 1,\n",
       " 'brainiest': 1,\n",
       " 'brainy': 1,\n",
       " 'brand-new': 1,\n",
       " 'brave': 1,\n",
       " 'bravery': 1,\n",
       " 'bravo': 1,\n",
       " 'breakthrough': 1,\n",
       " 'breakthroughs': 1,\n",
       " 'breathlessness': 1,\n",
       " 'breathtaking': 1,\n",
       " 'breathtakingly': 1,\n",
       " 'breeze': 1,\n",
       " 'bright': 1,\n",
       " 'brighten': 1,\n",
       " 'brighter': 1,\n",
       " 'brightest': 1,\n",
       " 'brilliance': 1,\n",
       " 'brilliances': 1,\n",
       " 'brilliant': 1,\n",
       " 'brilliantly': 1,\n",
       " 'brisk': 1,\n",
       " 'brotherly': 1,\n",
       " 'bullish': 1,\n",
       " 'buoyant': 1,\n",
       " 'cajole': 1,\n",
       " 'calm': 1,\n",
       " 'calming': 1,\n",
       " 'calmness': 1,\n",
       " 'capability': 1,\n",
       " 'capable': 1,\n",
       " 'capably': 1,\n",
       " 'captivate': 1,\n",
       " 'captivating': 1,\n",
       " 'carefree': 1,\n",
       " 'cashback': 1,\n",
       " 'cashbacks': 1,\n",
       " 'catchy': 1,\n",
       " 'celebrate': 1,\n",
       " 'celebrated': 1,\n",
       " 'celebration': 1,\n",
       " 'celebratory': 1,\n",
       " 'champ': 1,\n",
       " 'champion': 1,\n",
       " 'charisma': 1,\n",
       " 'charismatic': 1,\n",
       " 'charitable': 1,\n",
       " 'charm': 1,\n",
       " 'charming': 1,\n",
       " 'charmingly': 1,\n",
       " 'chaste': 1,\n",
       " 'cheaper': 1,\n",
       " 'cheapest': 1,\n",
       " 'cheer': 1,\n",
       " 'cheerful': 1,\n",
       " 'cheery': 1,\n",
       " 'cherish': 1,\n",
       " 'cherished': 1,\n",
       " 'cherub': 1,\n",
       " 'chic': 1,\n",
       " 'chivalrous': 1,\n",
       " 'chivalry': 1,\n",
       " 'civility': 1,\n",
       " 'civilize': 1,\n",
       " 'clarity': 1,\n",
       " 'classic': 1,\n",
       " 'classy': 1,\n",
       " 'clean': 1,\n",
       " 'cleaner': 1,\n",
       " 'cleanest': 1,\n",
       " 'cleanliness': 1,\n",
       " 'cleanly': 1,\n",
       " 'clear': 1,\n",
       " 'clear-cut': 1,\n",
       " 'cleared': 1,\n",
       " 'clearer': 1,\n",
       " 'clearly': 1,\n",
       " 'clears': 1,\n",
       " 'clever': 1,\n",
       " 'cleverly': 1,\n",
       " 'cohere': 1,\n",
       " 'coherence': 1,\n",
       " 'coherent': 1,\n",
       " 'cohesive': 1,\n",
       " 'colorful': 1,\n",
       " 'comely': 1,\n",
       " 'comfort': 1,\n",
       " 'comfortable': 1,\n",
       " 'comfortably': 1,\n",
       " 'comforting': 1,\n",
       " 'comfy': 1,\n",
       " 'commend': 1,\n",
       " 'commendable': 1,\n",
       " 'commendably': 1,\n",
       " 'commitment': 1,\n",
       " 'commodious': 1,\n",
       " 'compact': 1,\n",
       " 'compactly': 1,\n",
       " 'compassion': 1,\n",
       " 'compassionate': 1,\n",
       " 'compatible': 1,\n",
       " 'competitive': 1,\n",
       " 'complement': 1,\n",
       " 'complementary': 1,\n",
       " 'complemented': 1,\n",
       " 'complements': 1,\n",
       " 'compliant': 1,\n",
       " 'compliment': 1,\n",
       " 'complimentary': 1,\n",
       " 'comprehensive': 1,\n",
       " 'conciliate': 1,\n",
       " 'conciliatory': 1,\n",
       " 'concise': 1,\n",
       " 'confidence': 1,\n",
       " 'confident': 1,\n",
       " 'congenial': 1,\n",
       " 'congratulate': 1,\n",
       " 'congratulation': 1,\n",
       " 'congratulations': 1,\n",
       " 'congratulatory': 1,\n",
       " 'conscientious': 1,\n",
       " 'considerate': 1,\n",
       " 'consistent': 1,\n",
       " 'consistently': 1,\n",
       " 'constructive': 1,\n",
       " 'consummate': 1,\n",
       " 'contentment': 1,\n",
       " 'continuity': 1,\n",
       " 'contrasty': 1,\n",
       " 'contribution': 1,\n",
       " 'convenience': 1,\n",
       " 'convenient': 1,\n",
       " 'conveniently': 1,\n",
       " 'convience': 1,\n",
       " 'convienient': 1,\n",
       " 'convient': 1,\n",
       " 'convincing': 1,\n",
       " 'convincingly': 1,\n",
       " 'cool': 1,\n",
       " 'coolest': 1,\n",
       " 'cooperative': 1,\n",
       " 'cooperatively': 1,\n",
       " 'cornerstone': 1,\n",
       " 'correct': 1,\n",
       " 'correctly': 1,\n",
       " 'cost-effective': 1,\n",
       " 'cost-saving': 1,\n",
       " 'counter-attack': 1,\n",
       " 'counter-attacks': 1,\n",
       " 'courage': 1,\n",
       " 'courageous': 1,\n",
       " 'courageously': 1,\n",
       " 'courageousness': 1,\n",
       " 'courteous': 1,\n",
       " 'courtly': 1,\n",
       " 'covenant': 1,\n",
       " 'cozy': 1,\n",
       " 'creative': 1,\n",
       " 'credence': 1,\n",
       " 'credible': 1,\n",
       " 'crisp': 1,\n",
       " 'crisper': 1,\n",
       " 'cure': 1,\n",
       " 'cure-all': 1,\n",
       " 'cushy': 1,\n",
       " 'cute': 1,\n",
       " 'cuteness': 1,\n",
       " 'danke': 1,\n",
       " 'danken': 1,\n",
       " 'daring': 1,\n",
       " 'daringly': 1,\n",
       " 'darling': 1,\n",
       " 'dashing': 1,\n",
       " 'dauntless': 1,\n",
       " 'dawn': 1,\n",
       " 'dazzle': 1,\n",
       " 'dazzled': 1,\n",
       " 'dazzling': 1,\n",
       " 'dead-cheap': 1,\n",
       " 'dead-on': 1,\n",
       " 'decency': 1,\n",
       " 'decent': 1,\n",
       " 'decisive': 1,\n",
       " 'decisiveness': 1,\n",
       " 'dedicated': 1,\n",
       " 'defeat': 1,\n",
       " 'defeated': 1,\n",
       " 'defeating': 1,\n",
       " 'defeats': 1,\n",
       " 'defender': 1,\n",
       " 'deference': 1,\n",
       " 'deft': 1,\n",
       " 'deginified': 1,\n",
       " 'delectable': 1,\n",
       " 'delicacy': 1,\n",
       " 'delicate': 1,\n",
       " 'delicious': 1,\n",
       " 'delight': 1,\n",
       " 'delighted': 1,\n",
       " 'delightful': 1,\n",
       " 'delightfully': 1,\n",
       " 'delightfulness': 1,\n",
       " 'dependable': 1,\n",
       " 'dependably': 1,\n",
       " 'deservedly': 1,\n",
       " 'deserving': 1,\n",
       " 'desirable': 1,\n",
       " 'desiring': 1,\n",
       " 'desirous': 1,\n",
       " 'destiny': 1,\n",
       " 'detachable': 1,\n",
       " 'devout': 1,\n",
       " 'dexterous': 1,\n",
       " 'dexterously': 1,\n",
       " 'dextrous': 1,\n",
       " 'dignified': 1,\n",
       " 'dignify': 1,\n",
       " 'dignity': 1,\n",
       " 'diligence': 1,\n",
       " 'diligent': 1,\n",
       " 'diligently': 1,\n",
       " 'diplomatic': 1,\n",
       " 'dirt-cheap': 1,\n",
       " 'distinction': 1,\n",
       " 'distinctive': 1,\n",
       " 'distinguished': 1,\n",
       " 'diversified': 1,\n",
       " 'divine': 1,\n",
       " 'divinely': 1,\n",
       " 'dominate': 1,\n",
       " 'dominated': 1,\n",
       " 'dominates': 1,\n",
       " 'dote': 1,\n",
       " 'dotingly': 1,\n",
       " 'doubtless': 1,\n",
       " 'dreamland': 1,\n",
       " 'dumbfounded': 1,\n",
       " 'dumbfounding': 1,\n",
       " 'dummy-proof': 1,\n",
       " 'durable': 1,\n",
       " 'dynamic': 1,\n",
       " 'eager': 1,\n",
       " 'eagerly': 1,\n",
       " 'eagerness': 1,\n",
       " 'earnest': 1,\n",
       " 'earnestly': 1,\n",
       " 'earnestness': 1,\n",
       " 'ease': 1,\n",
       " 'eased': 1,\n",
       " 'eases': 1,\n",
       " 'easier': 1,\n",
       " 'easiest': 1,\n",
       " 'easiness': 1,\n",
       " 'easing': 1,\n",
       " 'easy': 1,\n",
       " 'easy-to-use': 1,\n",
       " 'easygoing': 1,\n",
       " 'ebullience': 1,\n",
       " 'ebullient': 1,\n",
       " 'ebulliently': 1,\n",
       " 'ecenomical': 1,\n",
       " 'economical': 1,\n",
       " 'ecstasies': 1,\n",
       " 'ecstasy': 1,\n",
       " 'ecstatic': 1,\n",
       " 'ecstatically': 1,\n",
       " 'edify': 1,\n",
       " 'educated': 1,\n",
       " 'effective': 1,\n",
       " 'effectively': 1,\n",
       " 'effectiveness': 1,\n",
       " 'effectual': 1,\n",
       " 'efficacious': 1,\n",
       " 'efficient': 1,\n",
       " 'efficiently': 1,\n",
       " 'effortless': 1,\n",
       " 'effortlessly': 1,\n",
       " 'effusion': 1,\n",
       " 'effusive': 1,\n",
       " 'effusively': 1,\n",
       " 'effusiveness': 1,\n",
       " 'elan': 1,\n",
       " 'elate': 1,\n",
       " 'elated': 1,\n",
       " 'elatedly': 1,\n",
       " 'elation': 1,\n",
       " 'electrify': 1,\n",
       " 'elegance': 1,\n",
       " 'elegant': 1,\n",
       " 'elegantly': 1,\n",
       " 'elevate': 1,\n",
       " 'elite': 1,\n",
       " 'eloquence': 1,\n",
       " 'eloquent': 1,\n",
       " 'eloquently': 1,\n",
       " 'embolden': 1,\n",
       " 'eminence': 1,\n",
       " 'eminent': 1,\n",
       " 'empathize': 1,\n",
       " 'empathy': 1,\n",
       " 'empower': 1,\n",
       " 'empowerment': 1,\n",
       " 'enchant': 1,\n",
       " 'enchanted': 1,\n",
       " 'enchanting': 1,\n",
       " 'enchantingly': 1,\n",
       " 'encourage': 1,\n",
       " 'encouragement': 1,\n",
       " 'encouraging': 1,\n",
       " 'encouragingly': 1,\n",
       " 'endear': 1,\n",
       " 'endearing': 1,\n",
       " 'endorse': 1,\n",
       " 'endorsed': 1,\n",
       " 'endorsement': 1,\n",
       " 'endorses': 1,\n",
       " 'endorsing': 1,\n",
       " 'energetic': 1,\n",
       " 'energize': 1,\n",
       " 'energy-efficient': 1,\n",
       " 'energy-saving': 1,\n",
       " 'engaging': 1,\n",
       " 'engrossing': 1,\n",
       " 'enhance': 1,\n",
       " 'enhanced': 1,\n",
       " 'enhancement': 1,\n",
       " 'enhances': 1,\n",
       " 'enjoy': 1,\n",
       " 'enjoyable': 1,\n",
       " 'enjoyably': 1,\n",
       " 'enjoyed': 1,\n",
       " 'enjoying': 1,\n",
       " 'enjoyment': 1,\n",
       " 'enjoys': 1,\n",
       " 'enlighten': 1,\n",
       " 'enlightenment': 1,\n",
       " 'enliven': 1,\n",
       " 'ennoble': 1,\n",
       " 'enough': 1,\n",
       " 'enrapt': 1,\n",
       " 'enrapture': 1,\n",
       " 'enraptured': 1,\n",
       " 'enrich': 1,\n",
       " 'enrichment': 1,\n",
       " 'enterprising': 1,\n",
       " 'entertain': 1,\n",
       " 'entertaining': 1,\n",
       " 'entertains': 1,\n",
       " 'enthral': 1,\n",
       " 'enthrall': 1,\n",
       " 'enthralled': 1,\n",
       " 'enthuse': 1,\n",
       " 'enthusiasm': 1,\n",
       " 'enthusiast': 1,\n",
       " 'enthusiastic': 1,\n",
       " 'enthusiastically': 1,\n",
       " 'entice': 1,\n",
       " 'enticed': 1,\n",
       " 'enticing': 1,\n",
       " 'enticingly': 1,\n",
       " 'entranced': 1,\n",
       " 'entrancing': 1,\n",
       " 'entrust': 1,\n",
       " 'enviable': 1,\n",
       " 'enviably': 1,\n",
       " 'envious': -1,\n",
       " 'enviously': -1,\n",
       " 'enviousness': -1,\n",
       " 'envy': 1,\n",
       " 'equitable': 1,\n",
       " 'ergonomical': 1,\n",
       " 'err-free': 1,\n",
       " 'erudite': 1,\n",
       " 'ethical': 1,\n",
       " 'eulogize': 1,\n",
       " 'euphoria': 1,\n",
       " 'euphoric': 1,\n",
       " 'euphorically': 1,\n",
       " 'evaluative': 1,\n",
       " 'evenly': 1,\n",
       " 'eventful': 1,\n",
       " 'everlasting': 1,\n",
       " 'evocative': 1,\n",
       " 'exalt': 1,\n",
       " 'exaltation': 1,\n",
       " 'exalted': 1,\n",
       " 'exaltedly': 1,\n",
       " 'exalting': 1,\n",
       " 'exaltingly': 1,\n",
       " 'examplar': 1,\n",
       " 'examplary': 1,\n",
       " 'excallent': 1,\n",
       " 'exceed': 1,\n",
       " 'exceeded': 1,\n",
       " 'exceeding': 1,\n",
       " 'exceedingly': 1,\n",
       " 'exceeds': 1,\n",
       " 'excel': 1,\n",
       " 'exceled': 1,\n",
       " 'excelent': 1,\n",
       " 'excellant': 1,\n",
       " 'excelled': 1,\n",
       " 'excellence': 1,\n",
       " 'excellency': 1,\n",
       " 'excellent': 1,\n",
       " 'excellently': 1,\n",
       " 'excels': 1,\n",
       " 'exceptional': 1,\n",
       " 'exceptionally': 1,\n",
       " 'excite': 1,\n",
       " 'excited': 1,\n",
       " 'excitedly': 1,\n",
       " 'excitedness': 1,\n",
       " 'excitement': 1,\n",
       " 'excites': 1,\n",
       " 'exciting': 1,\n",
       " 'excitingly': 1,\n",
       " 'exellent': 1,\n",
       " 'exemplar': 1,\n",
       " 'exemplary': 1,\n",
       " 'exhilarate': 1,\n",
       " 'exhilarating': 1,\n",
       " 'exhilaratingly': 1,\n",
       " 'exhilaration': 1,\n",
       " 'exonerate': 1,\n",
       " 'expansive': 1,\n",
       " 'expeditiously': 1,\n",
       " 'expertly': 1,\n",
       " 'exquisite': 1,\n",
       " 'exquisitely': 1,\n",
       " 'extol': 1,\n",
       " 'extoll': 1,\n",
       " 'extraordinarily': 1,\n",
       " 'extraordinary': 1,\n",
       " 'exuberance': 1,\n",
       " 'exuberant': 1,\n",
       " 'exuberantly': 1,\n",
       " 'exult': 1,\n",
       " 'exultant': 1,\n",
       " 'exultation': 1,\n",
       " 'exultingly': 1,\n",
       " 'eye-catch': 1,\n",
       " 'eye-catching': 1,\n",
       " 'eyecatch': 1,\n",
       " 'eyecatching': 1,\n",
       " 'fabulous': 1,\n",
       " 'fabulously': 1,\n",
       " 'facilitate': 1,\n",
       " 'fair': 1,\n",
       " 'fairly': 1,\n",
       " 'fairness': 1,\n",
       " 'faith': 1,\n",
       " 'faithful': 1,\n",
       " 'faithfully': 1,\n",
       " 'faithfulness': 1,\n",
       " 'fame': 1,\n",
       " 'famed': 1,\n",
       " 'famous': 1,\n",
       " 'famously': 1,\n",
       " 'fancier': 1,\n",
       " 'fancinating': 1,\n",
       " 'fancy': 1,\n",
       " 'fanfare': 1,\n",
       " 'fans': 1,\n",
       " 'fantastic': 1,\n",
       " 'fantastically': 1,\n",
       " 'fascinate': 1,\n",
       " 'fascinating': 1,\n",
       " 'fascinatingly': 1,\n",
       " 'fascination': 1,\n",
       " 'fashionable': 1,\n",
       " 'fashionably': 1,\n",
       " 'fast': 1,\n",
       " 'fast-growing': 1,\n",
       " 'fast-paced': 1,\n",
       " 'faster': 1,\n",
       " 'fastest': 1,\n",
       " 'fastest-growing': 1,\n",
       " 'faultless': 1,\n",
       " 'fav': 1,\n",
       " 'fave': 1,\n",
       " 'favor': 1,\n",
       " 'favorable': 1,\n",
       " 'favored': 1,\n",
       " 'favorite': 1,\n",
       " 'favorited': 1,\n",
       " 'favour': 1,\n",
       " 'fearless': 1,\n",
       " 'fearlessly': 1,\n",
       " 'feasible': 1,\n",
       " 'feasibly': 1,\n",
       " 'feat': 1,\n",
       " 'feature-rich': 1,\n",
       " 'fecilitous': 1,\n",
       " 'feisty': 1,\n",
       " 'felicitate': 1,\n",
       " 'felicitous': 1,\n",
       " 'felicity': 1,\n",
       " 'fertile': 1,\n",
       " 'fervent': 1,\n",
       " 'fervently': 1,\n",
       " 'fervid': 1,\n",
       " 'fervidly': 1,\n",
       " 'fervor': 1,\n",
       " 'festive': 1,\n",
       " 'fidelity': 1,\n",
       " 'fiery': 1,\n",
       " 'fine': 1,\n",
       " 'fine-looking': 1,\n",
       " 'finely': 1,\n",
       " 'finer': 1,\n",
       " 'finest': 1,\n",
       " 'firmer': 1,\n",
       " 'first-class': 1,\n",
       " 'first-in-class': 1,\n",
       " 'first-rate': 1,\n",
       " 'flashy': 1,\n",
       " 'flatter': 1,\n",
       " 'flattering': 1,\n",
       " 'flatteringly': 1,\n",
       " 'flawless': 1,\n",
       " 'flawlessly': 1,\n",
       " 'flexibility': 1,\n",
       " 'flexible': 1,\n",
       " 'flourish': 1,\n",
       " 'flourishing': 1,\n",
       " 'fluent': 1,\n",
       " 'flutter': 1,\n",
       " 'fond': 1,\n",
       " 'fondly': 1,\n",
       " 'fondness': 1,\n",
       " 'foolproof': 1,\n",
       " 'foremost': 1,\n",
       " 'foresight': 1,\n",
       " 'formidable': 1,\n",
       " 'fortitude': 1,\n",
       " 'fortuitous': 1,\n",
       " 'fortuitously': 1,\n",
       " 'fortunate': 1,\n",
       " 'fortunately': 1,\n",
       " 'fortune': 1,\n",
       " 'fragrant': 1,\n",
       " 'free': 1,\n",
       " 'freed': 1,\n",
       " 'freedom': 1,\n",
       " 'freedoms': 1,\n",
       " 'fresh': 1,\n",
       " 'fresher': 1,\n",
       " 'freshest': 1,\n",
       " 'friendliness': 1,\n",
       " 'friendly': 1,\n",
       " 'frolic': 1,\n",
       " 'frugal': 1,\n",
       " 'fruitful': 1,\n",
       " 'ftw': 1,\n",
       " 'fulfillment': 1,\n",
       " 'fun': 1,\n",
       " 'futurestic': 1,\n",
       " 'futuristic': 1,\n",
       " 'gaiety': 1,\n",
       " 'gaily': 1,\n",
       " 'gain': 1,\n",
       " 'gained': 1,\n",
       " 'gainful': 1,\n",
       " 'gainfully': 1,\n",
       " 'gaining': 1,\n",
       " 'gains': 1,\n",
       " 'gallant': 1,\n",
       " 'gallantly': 1,\n",
       " 'galore': 1,\n",
       " 'geekier': 1,\n",
       " 'geeky': 1,\n",
       " 'gem': 1,\n",
       " 'gems': 1,\n",
       " 'generosity': 1,\n",
       " 'generous': 1,\n",
       " 'generously': 1,\n",
       " 'genial': 1,\n",
       " 'genius': 1,\n",
       " 'gentle': 1,\n",
       " 'gentlest': 1,\n",
       " 'genuine': 1,\n",
       " 'gifted': 1,\n",
       " 'glad': 1,\n",
       " 'gladden': 1,\n",
       " 'gladly': 1,\n",
       " 'gladness': 1,\n",
       " 'glamorous': 1,\n",
       " 'glee': 1,\n",
       " 'gleeful': 1,\n",
       " 'gleefully': 1,\n",
       " 'glimmer': 1,\n",
       " 'glimmering': 1,\n",
       " 'glisten': 1,\n",
       " 'glistening': 1,\n",
       " 'glitter': 1,\n",
       " 'glitz': 1,\n",
       " 'glorify': 1,\n",
       " 'glorious': 1,\n",
       " 'gloriously': 1,\n",
       " 'glory': 1,\n",
       " 'glow': 1,\n",
       " 'glowing': 1,\n",
       " 'glowingly': 1,\n",
       " 'god-given': 1,\n",
       " 'god-send': 1,\n",
       " 'godlike': 1,\n",
       " 'godsend': 1,\n",
       " 'gold': 1,\n",
       " 'golden': 1,\n",
       " 'good': 1,\n",
       " 'goodly': 1,\n",
       " 'goodness': 1,\n",
       " 'goodwill': 1,\n",
       " 'goood': 1,\n",
       " 'gooood': 1,\n",
       " 'gorgeous': 1,\n",
       " 'gorgeously': 1,\n",
       " 'grace': 1,\n",
       " 'graceful': 1,\n",
       " 'gracefully': 1,\n",
       " 'gracious': 1,\n",
       " 'graciously': 1,\n",
       " 'graciousness': 1,\n",
       " 'grand': 1,\n",
       " 'grandeur': 1,\n",
       " 'grateful': 1,\n",
       " 'gratefully': 1,\n",
       " 'gratification': 1,\n",
       " 'gratified': 1,\n",
       " 'gratifies': 1,\n",
       " 'gratify': 1,\n",
       " 'gratifying': 1,\n",
       " 'gratifyingly': 1,\n",
       " 'gratitude': 1,\n",
       " 'great': 1,\n",
       " 'greatest': 1,\n",
       " 'greatness': 1,\n",
       " 'grin': 1,\n",
       " 'groundbreaking': 1,\n",
       " 'guarantee': 1,\n",
       " 'guidance': 1,\n",
       " 'guiltless': 1,\n",
       " 'gumption': 1,\n",
       " 'gush': 1,\n",
       " 'gusto': 1,\n",
       " 'gutsy': 1,\n",
       " 'hail': 1,\n",
       " 'halcyon': 1,\n",
       " 'hale': 1,\n",
       " 'hallmark': 1,\n",
       " 'hallmarks': 1,\n",
       " 'hallowed': 1,\n",
       " 'handier': 1,\n",
       " 'handily': 1,\n",
       " 'hands-down': 1,\n",
       " 'handsome': 1,\n",
       " 'handsomely': 1,\n",
       " 'handy': 1,\n",
       " 'happier': 1,\n",
       " 'happily': 1,\n",
       " 'happiness': 1,\n",
       " 'happy': 1,\n",
       " 'hard-working': 1,\n",
       " 'hardier': 1,\n",
       " 'hardy': 1,\n",
       " 'harmless': 1,\n",
       " 'harmonious': 1,\n",
       " 'harmoniously': 1,\n",
       " 'harmonize': 1,\n",
       " 'harmony': 1,\n",
       " 'headway': 1,\n",
       " 'heal': 1,\n",
       " 'healthful': 1,\n",
       " 'healthy': 1,\n",
       " 'hearten': 1,\n",
       " 'heartening': 1,\n",
       " 'heartfelt': 1,\n",
       " 'heartily': 1,\n",
       " 'heartwarming': 1,\n",
       " 'heaven': 1,\n",
       " 'heavenly': 1,\n",
       " 'helped': 1,\n",
       " 'helpful': 1,\n",
       " 'helping': 1,\n",
       " 'hero': 1,\n",
       " 'heroic': 1,\n",
       " 'heroically': 1,\n",
       " 'heroine': 1,\n",
       " 'heroize': 1,\n",
       " 'heros': 1,\n",
       " 'high-quality': 1,\n",
       " 'high-spirited': 1,\n",
       " 'hilarious': 1,\n",
       " 'holy': 1,\n",
       " 'homage': 1,\n",
       " 'honest': 1,\n",
       " 'honesty': 1,\n",
       " 'honor': 1,\n",
       " 'honorable': 1,\n",
       " 'honored': 1,\n",
       " 'honoring': 1,\n",
       " 'hooray': 1,\n",
       " 'hopeful': 1,\n",
       " 'hospitable': 1,\n",
       " 'hot': 1,\n",
       " 'hotcake': 1,\n",
       " 'hotcakes': 1,\n",
       " 'hottest': 1,\n",
       " 'hug': 1,\n",
       " 'humane': 1,\n",
       " 'humble': 1,\n",
       " 'humility': 1,\n",
       " 'humor': 1,\n",
       " 'humorous': 1,\n",
       " 'humorously': 1,\n",
       " 'humour': 1,\n",
       " 'humourous': 1,\n",
       " 'ideal': 1,\n",
       " 'idealize': 1,\n",
       " 'ideally': 1,\n",
       " 'idol': 1,\n",
       " 'idolize': 1,\n",
       " 'idolized': 1,\n",
       " 'idyllic': 1,\n",
       " 'illuminate': 1,\n",
       " 'illuminati': 1,\n",
       " 'illuminating': 1,\n",
       " 'illumine': 1,\n",
       " 'illustrious': 1,\n",
       " 'ilu': 1,\n",
       " 'imaculate': 1,\n",
       " 'imaginative': 1,\n",
       " 'immaculate': 1,\n",
       " 'immaculately': 1,\n",
       " 'immense': 1,\n",
       " 'impartial': 1,\n",
       " 'impartiality': 1,\n",
       " 'impartially': 1,\n",
       " 'impassioned': 1,\n",
       " 'impeccable': 1,\n",
       " 'impeccably': 1,\n",
       " 'important': 1,\n",
       " 'impress': 1,\n",
       " 'impressed': 1,\n",
       " 'impresses': 1,\n",
       " 'impressive': 1,\n",
       " 'impressively': 1,\n",
       " 'impressiveness': 1,\n",
       " 'improve': 1,\n",
       " 'improved': 1,\n",
       " 'improvement': 1,\n",
       " 'improvements': 1,\n",
       " 'improves': 1,\n",
       " 'improving': 1,\n",
       " 'incredible': 1,\n",
       " 'incredibly': 1,\n",
       " 'indebted': 1,\n",
       " 'individualized': 1,\n",
       " 'indulgence': 1,\n",
       " 'indulgent': 1,\n",
       " 'industrious': 1,\n",
       " 'inestimable': 1,\n",
       " 'inestimably': 1,\n",
       " 'inexpensive': 1,\n",
       " 'infallibility': 1,\n",
       " 'infallible': 1,\n",
       " 'infallibly': 1,\n",
       " 'influential': 1,\n",
       " 'ingenious': 1,\n",
       " 'ingeniously': 1,\n",
       " 'ingenuity': 1,\n",
       " 'ingenuous': 1,\n",
       " 'ingenuously': 1,\n",
       " 'innocuous': 1,\n",
       " 'innovation': 1,\n",
       " 'innovative': 1,\n",
       " 'inpressed': 1,\n",
       " 'insightful': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the score of the given word\n",
    "### score of +1 is given if the word is found is positive \n",
    "### score of -1 is given if the word is found is negative\n",
    "### score of 0 is given if the word is not found in the dictionary\n",
    "\n",
    "def get_score_word(word):\n",
    "    word = word.lower()\n",
    "    if word in training_dictionary:\n",
    "        return training_dictionary[word]\n",
    "    \n",
    "    elif word in training_dictionary:\n",
    "        return training_dictionary[word]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 0),\n",
       " ('Classic', 1),\n",
       " ('War', 0),\n",
       " ('of', 0),\n",
       " ('the', 0),\n",
       " ('Worlds', 0),\n",
       " ('by', 0),\n",
       " ('Timothy', 0),\n",
       " ('Hines', 0),\n",
       " ('is', 0),\n",
       " ('a', 0),\n",
       " ('very', 0),\n",
       " ('entertaining', 1),\n",
       " ('film', 0),\n",
       " ('that', 0),\n",
       " ('obviously', 0),\n",
       " ('goes', 0),\n",
       " ('to', 0),\n",
       " ('great', 1),\n",
       " ('effort', 0),\n",
       " ('and', 0),\n",
       " ('lengths', 0),\n",
       " ('to', 0),\n",
       " ('faithfully', 1),\n",
       " ('recreate', 0),\n",
       " ('H', 0),\n",
       " ('G', 0),\n",
       " ('Wells', 0),\n",
       " ('classic', 1),\n",
       " ('book', 0),\n",
       " ('Mr', 0),\n",
       " ('Hines', 0),\n",
       " ('succeeds', 1),\n",
       " ('in', 0),\n",
       " ('doing', 0),\n",
       " ('so', 0),\n",
       " ('I', 0),\n",
       " ('and', 0),\n",
       " ('those', 0),\n",
       " ('who', 0),\n",
       " ('watched', 0),\n",
       " ('his', 0),\n",
       " ('film', 0),\n",
       " ('with', 0),\n",
       " ('me', 0),\n",
       " ('appreciated', 1),\n",
       " ('the', 0),\n",
       " ('fact', 0),\n",
       " ('that', 0),\n",
       " ('it', 0),\n",
       " ('was', 0),\n",
       " ('not', 0),\n",
       " ('the', 0),\n",
       " ('standard', 0),\n",
       " ('predictable', 0),\n",
       " ('Hollywood', 0),\n",
       " ('fare', 0),\n",
       " ('that', 0),\n",
       " ('comes', 0),\n",
       " ('out', 0),\n",
       " ('every', 0),\n",
       " ('year', 0),\n",
       " ('e', 0),\n",
       " ('g', 0),\n",
       " ('the', 0),\n",
       " ('Spielberg', 0),\n",
       " ('version', 0),\n",
       " ('with', 0),\n",
       " ('Tom', 0),\n",
       " ('Cruise', 0),\n",
       " ('that', 0),\n",
       " ('had', 0),\n",
       " ('only', 0),\n",
       " ('the', 0),\n",
       " ('slightest', 0),\n",
       " ('resemblance', 0),\n",
       " ('to', 0),\n",
       " ('the', 0),\n",
       " ('book', 0),\n",
       " ('Obviously', 0),\n",
       " ('everyone', 0),\n",
       " ('looks', 0),\n",
       " ('for', 0),\n",
       " ('different', 0),\n",
       " ('things', 0),\n",
       " ('in', 0),\n",
       " ('a', 0),\n",
       " ('movie', 0),\n",
       " ('Those', 0),\n",
       " ('who', 0),\n",
       " ('envision', 0),\n",
       " ('themselves', 0),\n",
       " ('as', 0),\n",
       " ('amateur', 0),\n",
       " ('critics', -1),\n",
       " ('look', 0),\n",
       " ('only', 0),\n",
       " ('to', 0),\n",
       " ('criticize', -1),\n",
       " ('everything', 0),\n",
       " ('they', 0),\n",
       " ('can', 0),\n",
       " ('Others', 0),\n",
       " ('rate', 0),\n",
       " ('a', 0),\n",
       " ('movie', 0),\n",
       " ('on', 0),\n",
       " ('more', 0),\n",
       " ('important', 1),\n",
       " ('bases', 0),\n",
       " ('like', 1),\n",
       " ('being', 0),\n",
       " ('entertained', 0),\n",
       " ('which', 0),\n",
       " ('is', 0),\n",
       " ('why', 0),\n",
       " ('most', 0),\n",
       " ('people', 0),\n",
       " ('never', 0),\n",
       " ('agree', 0),\n",
       " ('with', 0),\n",
       " ('the', 0),\n",
       " ('critics', -1),\n",
       " ('We', 0),\n",
       " ('enjoyed', 1),\n",
       " ('the', 0),\n",
       " ('effort', 0),\n",
       " ('Mr', 0),\n",
       " ('Hines', 0),\n",
       " ('put', 0),\n",
       " ('into', 0),\n",
       " ('being', 0),\n",
       " ('faithful', 1),\n",
       " ('to', 0),\n",
       " ('H', 0),\n",
       " ('G', 0),\n",
       " ('Wells', 0),\n",
       " ('classic', 1),\n",
       " ('novel', 0),\n",
       " ('and', 0),\n",
       " ('we', 0),\n",
       " ('found', 0),\n",
       " ('it', 0),\n",
       " ('to', 0),\n",
       " ('be', 0),\n",
       " ('very', 0),\n",
       " ('entertaining', 1),\n",
       " ('This', 0),\n",
       " ('made', 0),\n",
       " ('it', 0),\n",
       " ('easy', 1),\n",
       " ('to', 0),\n",
       " ('overlook', -1),\n",
       " ('what', 0),\n",
       " ('the', 0),\n",
       " ('critics', -1),\n",
       " ('perceive', 0),\n",
       " ('to', 0),\n",
       " ('be', 0),\n",
       " ('its', 0),\n",
       " ('shortcomings', -1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word,get_score_word(word)) for doc in split(movieReview[\"review\"][1]) for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using only unigrams for sentimental analysis\n",
    "## For any given paragraph, the text is splitted, score for each word is given and final score is also calculated\n",
    "\n",
    "def review_score(sentences):   \n",
    "    \n",
    "    if len(sentences)<=1:\n",
    "        return 0\n",
    "    else:\n",
    "        final_score = 0\n",
    "        tagged_sentences =  split(sentences)\n",
    "        \n",
    "        for sentence_tokens in tagged_sentences:    \n",
    "            total_score = 0\n",
    "            \n",
    "            for i,current_token in enumerate(sentence_tokens):\n",
    "                \n",
    "                token_score = get_score_word(current_token)\n",
    "                total_score = total_score + token_score\n",
    "\n",
    "            final_score = final_score + total_score\n",
    "    if(final_score) < 0 : return -1\n",
    "    elif(final_score)>0 : return 1\n",
    "    else : return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(review_score('I had a critical week'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Creating a separate column for storing the output of the sentiment for algorithm 1\n",
    "movieReview_head['new_score_algo1'] = movieReview_head.apply(lambda x:review_score(x['review']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  71.3\n",
      "Precision is: 68.36\n",
      "Recall is: 75.31\n",
      "F1 Score is: 71.67\n"
     ]
    }
   ],
   "source": [
    "## Accuracy Measurement for the unsupervised sentiment analysis algorithm \n",
    "print('Accuracy is: ',round(accuracy_score(movieReview_head['sentiment'],movieReview_head['new_score_algo1'])  * 100,2))\n",
    "print('Precision is:',round(precision_score(movieReview_head['sentiment'],movieReview_head['new_score_algo1']) * 100,2))\n",
    "print('Recall is:',round(recall_score(movieReview_head['sentiment'],movieReview_head['new_score_algo1']) * 100,2))\n",
    "print('F1 Score is:', round(f1_score(movieReview_head['sentiment'],movieReview_head['new_score_algo1']) * 100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#How to improve the results ?\n",
    "## For Example:\n",
    "## 1. I want a burrito so good\n",
    "## 2. I just had a burrito which was not good.\n",
    "\n",
    "print(review_score('I h|ad a burrito so good'))\n",
    "print(review_score('I just had a burrito which was not good'))\n",
    "\n",
    "#What about sentence 2 ? Is it actually positive?\n",
    "\n",
    "#Hence we can go to next algorithm using Bag of Words and Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2 : Using Bag of Words and Modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers_dictionary = {}\n",
    "modifiers_dictionary['very'] = 'inc'\n",
    "modifiers_dictionary['not'] = 'inv'\n",
    "modifiers_dictionary['too'] = 'inc'\n",
    "modifiers_dictionary['so'] = 'inc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give more options to improve the accuracy???\n",
    "#add incrementers and inverters \n",
    "def review_score(sentences):    \n",
    "    \n",
    "    if len(sentences)<2:\n",
    "        return 0\n",
    "    else:\n",
    "        final_list = []\n",
    "        tagged_sentences = split(sentences)\n",
    "        \n",
    "        for sentence_tokens in tagged_sentences:\n",
    "            total_score = 0\n",
    "            for i,current_token in enumerate(sentence_tokens):\n",
    "                \n",
    "                token_score = get_score_word(current_token)\n",
    "                previous_token = sentence_tokens[i-1] if i>1 else None \n",
    "                \n",
    "                if previous_token is not None:\n",
    "                    \n",
    "                    if previous_token in modifiers_dictionary and modifiers_dictionary[previous_token]=='inc':\n",
    "                        token_score *= 2.0\n",
    "                    elif previous_token in modifiers_dictionary and modifiers_dictionary[previous_token]=='dec':\n",
    "                        token_score /= 2.0\n",
    "                    elif previous_token in modifiers_dictionary and modifiers_dictionary[previous_token]=='inv':\n",
    "                        token_score *= -1.0\n",
    "                    else:\n",
    "                        pass\n",
    "                total_score +=token_score\n",
    "            final_list.append(total_score)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "#How to improve the results ?\n",
    "## For Example:\n",
    "## 1. I want a burrito so good\n",
    "## 2. I just had a burrito which was not good.\n",
    "\n",
    "#What about sentence 2 ? It is actually positive \n",
    "print(review_score('I want a burrito so good'))\n",
    "print(review_score('I just had a burrito which was not good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Creating a separate column for storing the output of the sentiment for algorithm 2\n",
    "movieReview_head['new_score_algo2'] = movieReview_head.apply(lambda x:review_score(x['review']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  71.7\n",
      "Precision is: 68.74\n",
      "Recall is: 75.73\n",
      "F1 Score is: 72.06\n"
     ]
    }
   ],
   "source": [
    "## Accuracy Measurement for the new algorithm with incrementers, decrementers and inverters\n",
    "\n",
    "print('Accuracy is: ',round(accuracy_score(movieReview_head['sentiment'],movieReview_head['new_score_algo2'])  * 100,2))\n",
    "print('Precision is:',round(precision_score(movieReview_head['sentiment'],movieReview_head['new_score_algo2']) * 100,2))\n",
    "print('Recall is:',round(recall_score(movieReview_head['sentiment'],movieReview_head['new_score_algo2']) * 100,2))\n",
    "print('F1 Score is:', round(f1_score(movieReview_head['sentiment'],movieReview_head['new_score_algo2']) * 100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Algorithms for Unsupervised Sentimental Analysis\n",
    "\n",
    "## Two algorithms for unsupervised sentimental analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3 : Textblob for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.8, subjectivity=0.75)\n",
      "Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "Sentiment(polarity=0.7, subjectivity=0.6000000000000001)\n",
      "Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)\n",
      "Sentiment(polarity=-0.9099999999999998, subjectivity=0.8666666666666667)\n",
      "Sentiment(polarity=0.4666666666666666, subjectivity=0.5666666666666668)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "### Output of TextBlob gives two scores\n",
    "## Polarity: Polarity ranges between -1 and 1\n",
    "## 1. Polarity score with negative value means negative statement\n",
    "## 2. Polarity score with positive value means positive statement\n",
    "## 3. Polarity score with 0 means neutral statement\n",
    "\n",
    "## Subjectivity: Subjectivity ranges between 0 and 1\n",
    "## Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information.\n",
    "## 1. Subjectivity score of 0 is Objective statement\n",
    "## 2. Subjectivity score of 1 is subjective statement\n",
    "\n",
    "statements =TextBlob(\"Analytics Vidhya is a great platform to learn data science\")\n",
    "print(statements.sentiment)\n",
    "\n",
    "statements =TextBlob(\"Mars is better than earth\")\n",
    "print(statements.sentiment)\n",
    "\n",
    "statements = TextBlob('The food here is good')\n",
    "print(statements.sentiment)\n",
    "\n",
    "statements = TextBlob('The food here is bad')\n",
    "print(statements.sentiment)\n",
    "\n",
    "statements = TextBlob('The food here is very bad')\n",
    "print(statements.sentiment)\n",
    "\n",
    "statements = TextBlob('I was feeling good earlier but I am not feeling good now')\n",
    "print(statements.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Textblob takes the input as sentences and returns two output\n",
    "### The scoring for each statement is calculated and if the score is more than 0 assuming that it is positive\n",
    "### if the score is less than 0 assuming that it is negative\n",
    "### the final score will be calculated based on the sum of the score across the sentences\n",
    "\n",
    "def textblob(sentences):\n",
    "    total_score = 0\n",
    "    \n",
    "    for sentence in sent_tokenize(sentences):\n",
    "        sentence = \"\".join([ch for ch in sentence if ord(ch)<= 128])\n",
    "\n",
    "        if sentence=='':\n",
    "            return 0\n",
    "        else:\n",
    "            sent_score = TextBlob(sentence).sentiment[0]\n",
    "        \n",
    "        total_score += sent_score\n",
    "    return 1 if total_score>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Creating a separate column for storing the output of textblob\n",
    "movieReview_head['textblob'] = movieReview_head.apply(lambda x:textblob(x['review']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  68.3\n",
      "Precision is: 61.16\n",
      "Recall is: 93.78\n",
      "F1 Score is: 74.04\n"
     ]
    }
   ],
   "source": [
    "## Accuracy Measurement for Textblob sentimental analysis\n",
    "\n",
    "print('Accuracy is: ',round(accuracy_score(movieReview_head['sentiment'],movieReview_head['textblob']) * 100,2))\n",
    "print('Precision is:',round(precision_score(movieReview_head['sentiment'],movieReview_head['textblob']) * 100,2))\n",
    "print('Recall is:',round(recall_score(movieReview_head['sentiment'],movieReview_head['textblob']) * 100,2))\n",
    "print('F1 Score is:', round(f1_score(movieReview_head['sentiment'],movieReview_head['textblob']) * 100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4: Vader Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "## Normal statement with neutral polarity\n",
    "sents = \"I just got a call from my boss - does he realise it's Saturday?\"\n",
    "print(sid.polarity_scores(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4404}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.209, 'neu': 0.791, 'pos': 0.0, 'compound': -0.4404}\n",
      "{'neg': 0.292, 'neu': 0.708, 'pos': 0.0, 'compound': -0.6739}\n"
     ]
    }
   ],
   "source": [
    "## Normal statement with neutral polarity \n",
    "## Let's try adding emoticons to the statement as well\n",
    "\n",
    "sents = \"I just got a call from my boss - does he realise it's Saturday? :(\"\n",
    "print(sid.polarity_scores(sents))\n",
    "\n",
    "## Adding an emoticons has changed the polarity of the statement\n",
    "sents = \"I just got a call from my boss - does he realise it's Saturday? WTF\"\n",
    "print(sid.polarity_scores(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.572, 'pos': 0.428, 'compound': 0.5777}\n",
      "{'neg': 0.473, 'neu': 0.527, 'pos': 0.0, 'compound': -0.6696}\n",
      "{'neg': 0.0, 'neu': 0.443, 'pos': 0.557, 'compound': 0.7783}\n"
     ]
    }
   ],
   "source": [
    "## Advantage of using Incrementers/ Decrementers, inverters, & capitalization\n",
    "sents = 'the food here is good'\n",
    "print(sid.polarity_scores(sents))\n",
    "\n",
    "## adding incrementer/decrementer words to the statement increases/decreases the sentiment of the statement\n",
    "sents = \"The food here is so good\"\n",
    "print(sid.polarity_scores(sents))\n",
    "\n",
    "sents = \"The food here is so bad\"\n",
    "print(sid.polarity_scores(sents))\n",
    "\n",
    "## It also considers the inverters before the keywords and increases/decreases the sentiment of the statement accordingly\n",
    "sents = \"'I was feeling good earlier but I am not feeling good now'\"\n",
    "print(sid.polarity_scores(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.518, 'pos': 0.482, 'compound': 0.6866}\n",
      "{'neg': 0.192, 'neu': 0.529, 'pos': 0.279, 'compound': 0.3222}\n",
      "{'neg': 0.0, 'neu': 0.49, 'pos': 0.51, 'compound': 0.8526}\n"
     ]
    }
   ],
   "source": [
    "## adding capitalization for a word increases the intensity of the word\n",
    "sents = \"The food here is so GOOD\"\n",
    "print(sid.polarity_scores(sents))\n",
    "\n",
    "## It also handles the 'but' & 'and' case to change the sentiment score accordingly\n",
    "print(sid.polarity_scores(\"The food is really GOOD! But the service is dreadful.\"))\n",
    "print(sid.polarity_scores(\"The food is really GOOD! and the service is awesome.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vader sentimental analysis\n",
    "\n",
    "def vaderSentiment(sentences):\n",
    "    total_score = 0\n",
    "    for sentence in sent_tokenize(sentences):\n",
    "        sentence = \"\".join([ch for ch in sentence if ord(ch)<= 128])\n",
    "        pos = neg =neu = sent_score= 0\n",
    "\n",
    "        if sentence=='':\n",
    "            return 0\n",
    "        else:\n",
    "            sent_score = sid.polarity_scores(sentence)\n",
    "            neg = sent_score['neg']\n",
    "            pos = sent_score['pos']\n",
    "            neu = sent_score['neu']\n",
    "        \n",
    "            if pos>=neg and pos>=neu:\n",
    "                sent_score = 1\n",
    "            elif neu>=pos and neu>= neg:\n",
    "                sent_score = 1\n",
    "            else:\n",
    "                sent_score = -1\n",
    "        \n",
    "        total_score += sent_score\n",
    "    return 1 if total_score>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rshars\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Creating a separate column for storing the output of vader sentimental analysis\n",
    "movieReview_head['vader'] = movieReview_head.apply(lambda x:vaderSentiment(x['review']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  48.2\n",
      "Precision is: 48.2\n",
      "Recall is: 100.0\n",
      "F1 Score is: 65.05\n"
     ]
    }
   ],
   "source": [
    "## Accuracy Measurement for the vader sentiment algorithm\n",
    "\n",
    "print('Accuracy is: ',round(accuracy_score(movieReview_head['sentiment'],movieReview_head['vader']) * 100,2))\n",
    "print('Precision is:',round(precision_score(movieReview_head['sentiment'],movieReview_head['vader']) * 100,2))\n",
    "print('Recall is:',round(recall_score(movieReview_head['sentiment'],movieReview_head['vader']) * 100,2))\n",
    "print('F1 Score is:', round(f1_score(movieReview_head['sentiment'],movieReview_head['vader']) * 100,2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
